{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import statistics\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "from itertools import product\n",
    "from skimage import measure\n",
    "from math import sqrt\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy import ndimage\n",
    "from skimage import io\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dpm_3d(\n",
    "    ground_truth: int, prediction: int, \n",
    "    size_threshold_low: int, size_threshold_up: int, scale: float,\n",
    "    weight_d, weight_s, weight_a):\n",
    "    '''\n",
    "    Returns the discrete protein metric (DPM) similarity score of two focal adhesion (FA) images.\n",
    "    \n",
    "            Parameters:\n",
    "                    ground_truth: A numpy array of stack containing membrane and ground truth FA\n",
    "                    prediction: A numpy array of stack containing membrane and predicted FA to be compared to ground truth\n",
    "                    size_threshold_low: An integer value for lower bound size threshold; any FAs with an area less than this value are dropped\n",
    "                    size_threshold_up: An integer value for upper bound size threshold; any FAs with an area higher than this value are dropped\n",
    "                    scale: A float value for image scale (microns/pixel)\n",
    "                    weight_d: A float value for importance weight to be applied for distribution measurement\n",
    "                    weight_s: A float value for importance weight to be applied for shape/size measurement\n",
    "                    weight_a: A float value for importance weight to be applied for angle measurement\n",
    "            \n",
    "            Returns:\n",
    "                    dpm: A numpy float value for the discrete protein metric score\n",
    "                    d: A numpy float value for the distribution measurement\n",
    "                    s: A numpy float value for the shape/size measurement\n",
    "                    a: A numpy float value for the angle measurement\n",
    "                    fa_binary_truth: A numpy array of the 2D FA projection ground truth image\n",
    "                    fa_binary_pred: A numpy array of the 2D FA projection predicted image\n",
    "    '''\n",
    "    \n",
    "    def euclidean_distance(row1: slice, row2: slice):\n",
    "        '''\n",
    "        Returns the euclidean distance between two coordinate points.\n",
    "        \n",
    "            Parameters:\n",
    "                    row1: A slice of a list containing a single coordinate point\n",
    "                    row2: A slice of a list containing another coordinate point\n",
    "            \n",
    "            Returns:\n",
    "                    sqrt(distance): A float value for the euclidean distance\n",
    "        '''\n",
    "        distance = 0.0\n",
    "        for i in range(len(row1)-1):\n",
    "            distance += (row1[i] - row2[i])**2\n",
    "        return sqrt(distance)\n",
    "\n",
    "    \n",
    "    def get_neighbors(train: list, test_row: slice, num_neighbors: int):\n",
    "        '''\n",
    "        Returns the n nearest neighbors for one coordinate point.\n",
    "        \n",
    "            Parameters:\n",
    "                    train: A list containing a set of coordinate points\n",
    "                    test_row: A slice of a list containing a single coordinate point\n",
    "                    num_neighbors: An integer value for the n nearest neighbors to be retreived\n",
    "            \n",
    "            Returns:\n",
    "                    neighbors: A list of coordinate points for the n nearest neighbors\n",
    "        '''\n",
    "        distances = list()\n",
    "        for train_row in train:\n",
    "            dist = euclidean_distance(test_row, train_row)\n",
    "            distances.append((train_row, dist))\n",
    "        distances.sort(key=lambda tup: tup[1])\n",
    "        neighbors = list()\n",
    "        for i in range(num_neighbors):\n",
    "            neighbors.append(distances[i][0])\n",
    "        return neighbors\n",
    "\n",
    "    \n",
    "    def fa_processing_stack(img: int, size_threshold_low: int, size_threshold_up: int, scale: float):\n",
    "        '''\n",
    "        Returns numpy arrays for the binary and segmented FA images from the raw FA images.\n",
    "\n",
    "            Parameters:\n",
    "                    img: A numpy array of stack containing raw FA\n",
    "                    size_threshold_low: An integer value for lower bound size threshold; any FAs with an area less than this value are dropped\n",
    "                    size_threshold_up: An integer value for upper bound size threshold; any FAs with an area higher than this value are dropped\n",
    "                    scale: A float value for image scale (microns/pixel)\n",
    "\n",
    "            Returns:\n",
    "                    new_stack: A numpy array of the 2D projection of the processed FA stack\n",
    "        '''\n",
    "        # Read image and extract FA channel into a new empty image\n",
    "        stack = img\n",
    "        new_stack = np.zeros((256, 256), dtype=np.uint8)\n",
    "        for i in range(len(stack)):\n",
    "            # Read single slice and extract to empty image\n",
    "            img = stack[i]\n",
    "            res = np.zeros((256, 256, 3))\n",
    "            res[:,:,1] = img[:,:,1]\n",
    "            # Apply a top hat filter with 3x3 rectangular kernel and place filtered image into a new empty image\n",
    "            filterSize =(3, 3)\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, filterSize)\n",
    "            tophat_img = cv2.morphologyEx(res[:,:,1], cv2.MORPH_TOPHAT, kernel)        \n",
    "            processed_img = res\n",
    "            processed_img[:,:,1] = tophat_img\n",
    "            # Binarize filtered FA image\n",
    "            ret, bw_img = cv2.threshold(processed_img,10,255,cv2.THRESH_BINARY)\n",
    "            gray = rgb2gray(bw_img)\n",
    "            gray = gray * 255\n",
    "            gray = gray.astype(np.uint8)\n",
    "            ret, out_l = cv2.threshold(gray,0,255,cv2.THRESH_BINARY)\n",
    "            # Find the contours of each FA\n",
    "            contours, hier = cv2.findContours(out_l, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            binary_img = np.zeros((256,256), dtype=np.uint8)\n",
    "            # Iterate through each contour\n",
    "            for cntr in contours:\n",
    "                # Use bouding rectangle to find width and height of each FA to calculate area\n",
    "                x,y,w,h = cv2.boundingRect(cntr)\n",
    "                w = w*scale\n",
    "                h = h*scale\n",
    "                area = w*h\n",
    "                # Write FAs that have an area that falls within established boundary into a new empty image\n",
    "                if size_threshold_low <= area <= size_threshold_up:\n",
    "                    cv2.drawContours(binary_img, [cntr], 0, (255, 0, 0), -1)\n",
    "            # Apply laplacian operator to binary FA image to obtain segmented FA image\n",
    "            kernel_laplace = np.array([np.array([1, 1, 1]), np.array([1, -8, 1]), np.array([1, 1, 1])])\n",
    "            seg_img = ndimage.convolve(binary_img, kernel_laplace, mode='constant')\n",
    "            seg_img = seg_img * 255\n",
    "            ret, seg_img = cv2.threshold(seg_img,10,255,cv2.THRESH_BINARY)\n",
    "            # Write processed slice into 2D projection\n",
    "            new_stack += binary_img\n",
    "        return new_stack\n",
    "    \n",
    "    \n",
    "    def membrane_processing(img: int):\n",
    "        '''\n",
    "        Returns numpy array for the segmented membrane image from the raw membrane image.\n",
    "        \n",
    "            Parameters:\n",
    "                    img: A numpy array of stack containing raw membrane\n",
    "            \n",
    "            Returns:\n",
    "                    output_img[index]: A numpy array of the slice containing membrane outline\n",
    "        '''\n",
    "        \n",
    "        output_img = np.zeros((len(img), 256, 256))\n",
    "        memb_slice = []\n",
    "        for i in range(len(img)):\n",
    "            # Read image and extract membrane channel to binarize\n",
    "            ret, bw_img = cv2.threshold(img[i,:,:,0],10,255,cv2.THRESH_BINARY)\n",
    "            # Place binary membrane channel into a new empty image\n",
    "            res = np.zeros((256, 256, 3))\n",
    "            res[:,:,0] = bw_img\n",
    "            gray = rgb2gray(res)\n",
    "            # Apply laplacian operator to binary membrane image to obtain segmented membrane image\n",
    "            kernel_laplace = np.array([np.array([1, 1, 1]), np.array([1, -8, 1]), np.array([1, 1, 1])])\n",
    "            out_l = ndimage.convolve(gray, kernel_laplace, mode='constant')\n",
    "            out_l = out_l * 255\n",
    "            ret, seg_img = cv2.threshold(out_l,10,255,cv2.THRESH_BINARY)\n",
    "            output_img[i] = seg_img\n",
    "            xs = range(seg_img.shape[0])\n",
    "            ys = range(seg_img.shape[1])\n",
    "            indices = np.array(list(product(xs, ys)))\n",
    "            memb_slice.append(len(indices))\n",
    "        index = memb_slice.index(max(memb_slice))\n",
    "        return output_img[index]\n",
    "    \n",
    "    \n",
    "    # Calculation of distribution (d) measurement\n",
    "    \n",
    "    # Apply membrane processing function to raw ground truth stack\n",
    "    membrane = membrane_processing(ground_truth)\n",
    "    # Obtain x-y coordinates for membrane outline from segmented membrane slice\n",
    "    pixels = membrane.reshape(-1)\n",
    "    xs = range(membrane.shape[0])\n",
    "    ys = range(membrane.shape[1])\n",
    "    indices = np.array(list(product(xs, ys)))\n",
    "    index = pd.Series(pixels, name=\"pixels\")\n",
    "    df = pd.DataFrame({\n",
    "        \"xmem\" : indices[:, 0],\n",
    "        \"ymem\" : indices[:, 1]\n",
    "    }, index=index)\n",
    "    df = df[df.index != 0]\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(columns=['pixels'])\n",
    "    x_values = df['xmem'].values\n",
    "    x_arr = np.reshape(x_values, (-1, 1))\n",
    "    y_values = df['ymem'].values\n",
    "    y_arr = np.reshape(y_values, (-1, 1))\n",
    "    if len(x_values) > 0:\n",
    "        # Obtain minimum and maximum x and y values\n",
    "        min_x = min(x_values)\n",
    "        max_x = max(x_values)\n",
    "        min_y = min(y_values)\n",
    "        max_y = max(y_values)\n",
    "        coordinates = np.hstack((x_arr, y_arr))\n",
    "        # Extract bounds for membrane outline into a list\n",
    "        coord_bound = []\n",
    "        for x in range(min_x, max_x):\n",
    "            new_coord = []\n",
    "            for i in range(len(coordinates)):\n",
    "                if coordinates[i][0] == x:\n",
    "                    new_coord.append(coordinates[i][1])\n",
    "            if len(new_coord) > 0:\n",
    "                y_min = min(new_coord)\n",
    "                y_max = max(new_coord)\n",
    "                coord_bound.append([x, y_min, y_max])\n",
    "\n",
    "    # Apply fa processing function to raw ground truth stack using size thresholds and scale defined in dpm function\n",
    "    fa_binary_truth = fa_processing_stack(ground_truth, size_threshold_low, size_threshold_up, scale)\n",
    "    # Segment FAs from 2D projection resulting from fa processing function\n",
    "    kernel_laplace = np.array([np.array([1, 1, 1]), np.array([1, -8, 1]), np.array([1, 1, 1])])\n",
    "    seg_img = ndimage.convolve(fa_binary_truth, kernel_laplace, mode='constant')\n",
    "    seg_img = seg_img * 255\n",
    "    ret, seg_img_truth = cv2.threshold(seg_img,10,255,cv2.THRESH_BINARY)\n",
    "    # Extract x-y coordinates for centroid of each ground truth FA site into a list\n",
    "    labels= measure.label(seg_img_truth, background=0)\n",
    "    bg_label = labels[0,0] \n",
    "    labels[labels==bg_label] = 0\n",
    "    props = measure.regionprops(labels)\n",
    "    centroids = np.zeros(shape=(len(np.unique(labels)) - 1,2))\n",
    "    for i,prop in enumerate(props):\n",
    "        my_centroid = prop.centroid\n",
    "        centr = [0, 0]\n",
    "        centr[0] = my_centroid[0]\n",
    "        centr[1] = my_centroid[1]\n",
    "        centroids[i,:]= centr\n",
    "    \n",
    "    # Train a k-means clustering algorithm using ground truth centroid coordinate data\n",
    "    # If FA number is less than 5, match number of clusters to number of FAs\n",
    "    if 0 < len(centroids) < 5:\n",
    "        kmeans = KMeans(n_clusters = len(centroids), init = 'k-means++', random_state = 42).fit(centroids)\n",
    "    # If FA number is greater or equal to 5, number of clusters is 5\n",
    "    elif len(centroids) >= 5:\n",
    "        kmeans = KMeans(n_clusters = 5, init = 'k-means++', random_state = 42).fit(centroids)\n",
    "\n",
    "    # Apply fa processing function to raw prediction stack using size thresholds and scale defined in dpm function\n",
    "    fa_binary_pred = fa_processing_stack(prediction, size_threshold_low, size_threshold_up, scale)\n",
    "    # Segment FAs from 2D projection resulting from fa processing function\n",
    "    kernel_laplace = np.array([np.array([1, 1, 1]), np.array([1, -8, 1]), np.array([1, 1, 1])])\n",
    "    seg_img = ndimage.convolve(fa_binary_pred, kernel_laplace, mode='constant')\n",
    "    seg_img = seg_img * 255\n",
    "    ret, seg_img_pred = cv2.threshold(seg_img,10,255,cv2.THRESH_BINARY)\n",
    "    # Extract x-y coordinates for centroid of each predicted FA site into a list\n",
    "    labels= measure.label(seg_img_pred, background=0)\n",
    "    bg_label = labels[0,0] \n",
    "    labels[labels==bg_label] = 0\n",
    "    props = measure.regionprops(labels)\n",
    "    centroids2 = np.zeros(shape=(len(np.unique(labels)) - 1,2))\n",
    "    for i,prop in enumerate(props):\n",
    "        my_centroid = prop.centroid\n",
    "        centr = [0, 0]\n",
    "        centr[0] = my_centroid[0]\n",
    "        centr[1] = my_centroid[1]\n",
    "        centroids2[i,:]= centr\n",
    "    # Iterate through all predicted FA centroids and only keep centroids that are inside of membrane outline in a new list\n",
    "    centroids_pred = []\n",
    "    for i in range(len(centroids2)):\n",
    "        if len(x_values) > 0:\n",
    "            for j in range(len(coord_bound)):\n",
    "                if int(centroids2[i][0]) == coord_bound[j][0] and coord_bound[j][1] <= int(centroids2[i][1]) <= coord_bound[j][2]:\n",
    "                    centroids_pred.append([centroids2[i][0], centroids2[i][1]])\n",
    "        else:\n",
    "            centroids_pred = centroids2\n",
    "    # Calculate number of dropped FAs and use as penalizing factor\n",
    "    dropped_number = len(centroids2) - len(centroids_pred)\n",
    "    if len(centroids2) > 0:\n",
    "        factor = 1 - (dropped_number/len(centroids2))\n",
    "    else:\n",
    "        factor = 0\n",
    "    # Use trained k-means clustering algorithm to predict to which cluster each predicted FA belongs to\n",
    "    if len(centroids2) > 0 and len(centroids) > 0:\n",
    "        pred_clusters = kmeans.predict(centroids2)\n",
    "        # Count number of predicted FAs on each cluster\n",
    "        unique_pred, counts_pred = np.unique(pred_clusters, return_counts=True)\n",
    "        # Count number of ground truth FAs on each cluster\n",
    "        truth_clusters = kmeans.labels_\n",
    "        unique_truth, counts_truth = np.unique(truth_clusters, return_counts=True)\n",
    "        # If a cluster has zero FAs, add zero to the counts list\n",
    "        clusters = []\n",
    "        if len(counts_truth) != len(counts_pred):\n",
    "            for j in range(len(counts_truth)-len(counts_pred)):\n",
    "                counts_pred = np.append(counts_pred, 0)\n",
    "        # Calculate the ratio of predicted FAs to ground truth FAs on each cluster\n",
    "        for i in range(len(counts_truth)):\n",
    "            cluster_ind = (min(counts_truth[i], counts_pred[i]))/(max(counts_truth[i], counts_pred[i]))\n",
    "            clusters.append(cluster_ind)\n",
    "        # Calculate d measurement by taking average of ratios for each cluster and multiply by penalizing factor\n",
    "        d = statistics.mean(clusters)\n",
    "    elif len(centroids2) == 0 and len(centroids) == 0:\n",
    "        d = 1\n",
    "    else:\n",
    "        d = 0\n",
    "    \n",
    "    # Calculation of shape/size (s) and angle (a) measurement\n",
    "    \n",
    "    # Use 2D FA projection obtained previously to draw bounding rectangles around each FA in prediction\n",
    "    segmented_fa = fa_binary_pred\n",
    "    segmented_fa_gray = rgb2gray(segmented_fa)\n",
    "    gray = segmented_fa_gray*255\n",
    "    gray = gray.astype(np.uint8)\n",
    "    # Find contours for each predicted FA site\n",
    "    ret, out_l = cv2.threshold(gray,0,255,cv2.THRESH_BINARY)\n",
    "    contours, hier = cv2.findContours(out_l, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    pred_img = np.zeros((256,256))\n",
    "    rect_coord = []\n",
    "    rect_dim = []\n",
    "    rect_angle = []\n",
    "    # Iterate through all predicted FA sites\n",
    "    for cntr in contours:\n",
    "        # Use bouding rectangle to obtain dimensions and coordinates of each FA site\n",
    "        x,y,w,h = cv2.boundingRect(cntr)\n",
    "        rect_coord.append([x,y])\n",
    "        rect_dim.append([w,h])\n",
    "        # Draw rectangles in a new image\n",
    "        cv2.rectangle(pred_img, (x, y), (x+w, y+h), (255, 0, 0), -1)\n",
    "        # Use minimum area rectangle to obtain angle of orientation of each FA site\n",
    "        center, dim, angle = cv2.minAreaRect(cntr)\n",
    "        rect_angle.append(angle)\n",
    "    \n",
    "    # Repeat same procedure as above to obtain dimensions, coordinates and angle of each ground truth FA site\n",
    "    segmented_fa_truth = fa_binary_truth\n",
    "    segmented_fa_truth_gray = rgb2gray(segmented_fa_truth)\n",
    "    gray = segmented_fa_truth_gray*255\n",
    "    gray = gray.astype(np.uint8)\n",
    "    ret, out_l = cv2.threshold(gray,0,255,cv2.THRESH_BINARY)\n",
    "    contours, hier = cv2.findContours(out_l, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    new_img = np.zeros((256,256))\n",
    "    rect_coord_truth = []\n",
    "    rect_dim_truth = []\n",
    "    rect_angle_truth = []\n",
    "    for cntr in contours:\n",
    "        x,y,w,h = cv2.boundingRect(cntr)\n",
    "        rect_coord_truth.append([x,y])\n",
    "        rect_dim_truth.append([w,h])\n",
    "        cv2.rectangle(new_img, (x, y), (x+w, y+h), (255, 0, 0), -1)\n",
    "        center, dim, angle = cv2.minAreaRect(cntr)\n",
    "        rect_angle_truth.append(angle)\n",
    "    \n",
    "    # Create new image to match location of FA sites in ground truth and prediction\n",
    "    ground_truth_centered_img = np.zeros((256,256))\n",
    "    angle_scores = []\n",
    "    # Iterate through all predicted FA sites\n",
    "    for i in range(len(rect_coord)):\n",
    "        # Obtain centroid coordinates for FA site\n",
    "        x_center = rect_coord[i][0] + rect_dim[i][0]//2\n",
    "        y_center = rect_coord[i][1] + rect_dim[i][1]//2\n",
    "        # Obtain nearest neighbor in the ground truth FA sites to the predicted FA site\n",
    "        neighbors = get_neighbors(rect_coord_truth, rect_coord[i], 1)\n",
    "        for neighbor in neighbors:\n",
    "            # Extract nearest neighbor position in the ground truth FA sites list\n",
    "            for j in range(len(rect_coord_truth)):\n",
    "                if neighbor[0] == rect_coord_truth[j][0] and neighbor[1] == rect_coord_truth[j][1]:\n",
    "                    # Obtain dimensions and centroid coordinates for nearest neighbor ground truth FA site\n",
    "                    w = rect_dim_truth[j][0]\n",
    "                    h = rect_dim_truth[j][1]\n",
    "                    x = x_center - w//2\n",
    "                    y = y_center - h//2\n",
    "                    # Write new image with ground truth FA sites located at same position as predicted FA sites\n",
    "                    cv2.rectangle(ground_truth_centered_img, (x, y), (x+w, y+h), (255, 0, 0), -1)\n",
    "                    # Obtain angle score by normalizing angle values to a range of 0-90 degrees\n",
    "                    if rect_angle[i] > 90:\n",
    "                        angle_pred = 180 - rect_angle[i]\n",
    "                    elif -90 <= rect_angle[i] < 0:\n",
    "                        angle_pred = abs(rect_angle[i])\n",
    "                    elif rect_angle[i] < -90:\n",
    "                        angle_pred = 180 - abs(rect_angle[i])\n",
    "                    else:\n",
    "                        angle_pred = rect_angle[i]\n",
    "                    if rect_angle_truth[j] > 90:\n",
    "                        angle_truth = 180 - rect_angle_truth[j]\n",
    "                    elif -90 <= rect_angle_truth[j] < 0:\n",
    "                        angle_truth = abs(rect_angle_truth[j])\n",
    "                    elif rect_angle_truth[j] < -90:\n",
    "                        angle_truth = 180 - abs(rect_angle_truth[j])\n",
    "                    else:\n",
    "                        angle_truth = rect_angle_truth[j]\n",
    "                    # Calculate deviation between predicted and ground truth FA site angle\n",
    "                    angle_dev = abs(angle_pred - angle_truth)\n",
    "                    angle_ind = 1 - (angle_dev/90)\n",
    "                    angle_scores.append(angle_ind)\n",
    "    \n",
    "    # Compare ground truth centered image to predicted image\n",
    "    y_true = ground_truth_centered_img.flatten()\n",
    "    y_true = y_true/255\n",
    "    y_pred = pred_img.flatten()\n",
    "    y_pred = y_pred/255\n",
    "    # Compute true positives, false negatives, and false positives\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    fp = 0\n",
    "    for k in range(len(y_true)):\n",
    "        if y_true[k]==1 and y_pred[k]==1:\n",
    "            tp += 1\n",
    "        elif y_true[k]==1 and y_pred[k]==0:\n",
    "            fn += 1\n",
    "        elif y_true[k]==0 and y_pred[k]==1:\n",
    "            fp += 1\n",
    "    # Calculate precision and recall\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    # Calculate s measurement using F1 score\n",
    "    s = (2*precision*recall)/(precision+recall)\n",
    "    # Calculate a measurement by taking averge of angle scores across all FA sites\n",
    "    a = statistics.mean(angle_scores)\n",
    "\n",
    "    # Calculate dpm score using defined weights and obtained d, s, and a measurements\n",
    "    if d == 1 or s == 1 or a == 1:\n",
    "        dpm = 1\n",
    "    elif d == 0 or s == 0 or a == 0:\n",
    "        dpm = 0\n",
    "    else:\n",
    "        dpm = (weight_d*d)+(weight_s*s)+(weight_a*a)\n",
    "    \n",
    "    \n",
    "    return dpm, d, s, a, fa_binary_truth, fa_binary_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fa_nd(\n",
    "    nucleus_truth: int, nucleus_prediction: int,\n",
    "    fa_truth: int, fa_prediction: int,\n",
    "    size_threshold_low: int, size_threshold_up: int, scale: float):\n",
    "    '''\n",
    "    Returns the FA-Nucleus Distribution (FA-ND) score for subcellular distribution similarity between true cell and digital twin.\n",
    "    \n",
    "            Parameters:\n",
    "                    nucleus_truth: A numpy array of stack containing ground truth nucleus\n",
    "                    nucleus_prediction: A numpy array of stack containing predicted nucleus\n",
    "                    fa_truth: A numpy array of stack containing ground truth FA sites\n",
    "                    fa_prediction: A numpy array of stack containing predicted FA sites\n",
    "                    size_threshold_low: An integer value for lower bound size threshold; any FAs with an area less than this value are dropped\n",
    "                    size_threshold_up: An integer value for upper bound size threshold; any FAs with an area higher than this value are dropped\n",
    "                    scale: A float value for image scale (microns/pixel)\n",
    "            \n",
    "            Returns:\n",
    "                    fa_nd: A numpy float value for the FA-Nucleus Distribution score\n",
    "    '''\n",
    "    \n",
    "    def euclidean_distance(row1: slice, row2: slice):\n",
    "        '''\n",
    "        Returns the euclidean distance between two coordinate points.\n",
    "        \n",
    "            Parameters:\n",
    "                    row1: A slice of a list containing a single coordinate point\n",
    "                    row2: A slice of a list containing another coordinate point\n",
    "            \n",
    "            Returns:\n",
    "                    sqrt(distance): A float value for the euclidean distance\n",
    "        '''\n",
    "        distance = 0.0\n",
    "        for i in range(len(row1)-1):\n",
    "            distance += (row1[i] - row2[i])**2\n",
    "        return sqrt(distance)\n",
    "\n",
    "    \n",
    "    def nucl_centroid(img: int):\n",
    "        '''\n",
    "        Returns x-y coordinates of nucleus centroid from raw nucleus image.\n",
    "\n",
    "            Parameters:\n",
    "                    img: A numpy array of the image containing raw nucleus\n",
    "\n",
    "            Returns:\n",
    "                    centroids: Nucleus centroid x-y coordinates\n",
    "        '''\n",
    "        # Convert nucleus image into 8-bit image\n",
    "        nucleus = np.uint8(img)\n",
    "        # Binarize nucleus image and place into empty image\n",
    "        ret, bw_img = cv2.threshold(nucleus[20,:,:,2],20,255,cv2.THRESH_BINARY)\n",
    "        res = np.zeros((256, 256, 3))\n",
    "        res[:,:,2] = bw_img\n",
    "        gray = rgb2gray(res)\n",
    "        # Apply laplacian operator to binary nucleus image to obtain nucleus outline image\n",
    "        kernel_laplace = np.array([np.array([1, 1, 1]), np.array([1, -8, 1]), np.array([1, 1, 1])])\n",
    "        out_l = ndimage.convolve(gray, kernel_laplace, mode='constant')\n",
    "        out_l = out_l * 255\n",
    "        ret, seg_img = cv2.threshold(out_l,10,255,cv2.THRESH_BINARY)\n",
    "        # Extract x-y coordinates of nucleus centroid from nucleus outline image\n",
    "        labels= measure.label(seg_img, background=0)\n",
    "        bg_label = labels[0,0] \n",
    "        labels[labels==bg_label] = 0\n",
    "        props = measure.regionprops(labels)\n",
    "        centroids = np.zeros(shape=(len(np.unique(labels)) - 1,2))\n",
    "        for i,prop in enumerate(props):\n",
    "            my_centroid = prop.centroid\n",
    "            centr = [0, 0]\n",
    "            centr[0] = my_centroid[0]\n",
    "            centr[1] = my_centroid[1]\n",
    "            centroids[i,:]= centr\n",
    "        return centroids\n",
    "\n",
    "    \n",
    "    def fa_centroids(img: int, size_threshold_low: int, size_threshold_up: int, scale: float):\n",
    "        '''\n",
    "        Returns x-y coordinates of each FA site from raw FA image.\n",
    "\n",
    "            Parameters:\n",
    "                    img: A numpy array of the image containing raw FA\n",
    "                    size_threshold_low: An integer value for lower bound size threshold; any FAs with an area less than this value are dropped\n",
    "                    size_threshold_up: An integer value for upper bound size threshold; any FAs with an area higher than this value are dropped\n",
    "                    scale: A float value for image scale (microns/pixel)\n",
    "\n",
    "            Returns:\n",
    "                    centroids: FA sites centroids x-y coordinates\n",
    "        '''\n",
    "        # Read FA stack\n",
    "        stack = img\n",
    "        new_stack = np.zeros((256, 256), dtype=np.uint8)\n",
    "        # Iterate through each slice in FA stack\n",
    "        for i in range(len(stack)):\n",
    "            img = stack[i]\n",
    "            res = np.zeros((256, 256, 3))\n",
    "            res[:,:,1] = img[:,:,1]\n",
    "            # Apply a top hat filter with 3x3 rectangular kernel and place filtered image into a new empty image\n",
    "            filterSize =(3, 3)\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, filterSize)\n",
    "            tophat_img = cv2.morphologyEx(res[:,:,1], cv2.MORPH_TOPHAT, kernel)        \n",
    "            processed_img = res\n",
    "            processed_img[:,:,1] = tophat_img\n",
    "            # Binarize filtered FA image\n",
    "            ret, bw_img = cv2.threshold(processed_img,10,255,cv2.THRESH_BINARY)\n",
    "            gray = rgb2gray(bw_img)\n",
    "            gray = gray * 255\n",
    "            gray = gray.astype(np.uint8)\n",
    "            ret, out_l = cv2.threshold(gray,0,255,cv2.THRESH_BINARY)\n",
    "            # Find the contours of each FA\n",
    "            contours, hier = cv2.findContours(out_l, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            binary_img = np.zeros((256,256), dtype=np.uint8)\n",
    "            # Iterate through each contour\n",
    "            for cntr in contours:\n",
    "                # Use bouding rectangle to find width and height of each FA to calculate area\n",
    "                x,y,w,h = cv2.boundingRect(cntr)\n",
    "                w = w*scale\n",
    "                h = h*scale\n",
    "                area = w*h\n",
    "                # Write FAs that have an area within the established thresholds into a new empty image\n",
    "                if size_threshold_low <= area <= size_threshold_up:\n",
    "                    cv2.drawContours(binary_img, [cntr], 0, (255, 0, 0), -1)\n",
    "            # Add binary FA slice into empty image to create 2D projection of FA sites\n",
    "            new_stack += binary_img\n",
    "        # Apply Laplacian operator to segment FA sites from 2D projection\n",
    "        kernel_laplace = np.array([np.array([1, 1, 1]), np.array([1, -8, 1]), np.array([1, 1, 1])])\n",
    "        seg_img = ndimage.convolve(new_stack, kernel_laplace, mode='constant')\n",
    "        seg_img = seg_img * 255\n",
    "        # Extract x-y coordinates of FA centroids from segmented FA image\n",
    "        ret, seg_img = cv2.threshold(seg_img,10,255,cv2.THRESH_BINARY)\n",
    "        labels= measure.label(seg_img, background=0)\n",
    "        bg_label = labels[0,0] \n",
    "        labels[labels==bg_label] = 0\n",
    "        props = measure.regionprops(labels)\n",
    "        centroids = np.zeros(shape=(len(np.unique(labels)) - 1,2))\n",
    "        for i,prop in enumerate(props):\n",
    "            my_centroid = prop.centroid\n",
    "            centr = [0, 0]\n",
    "            centr[0] = my_centroid[0]\n",
    "            centr[1] = my_centroid[1]\n",
    "            centroids[i,:]= centr\n",
    "        return centroids\n",
    "    \n",
    "    \n",
    "    # Extract nucleus and FAs centroids from ground truth\n",
    "    fa_centroids_truth = fa_centroids(fa_truth, size_threshold_low, size_threshold_up, scale)\n",
    "    nucl_centroid_truth = nucl_centroid(nucleus_truth)\n",
    "    # Calculate Eucleidean distance between nucleus centroid and centroid of each FA\n",
    "    distance_truth = []\n",
    "    for i in range(len(fa_centroids_truth)):\n",
    "        distance_truth.append(euclidean_distance(nucl_centroid_truth[0], fa_centroids_truth[i]))\n",
    "    # Extract nucleus and FAs centroids from prediction\n",
    "    fa_centroids_pred = fa_centroids(fa_prediction, size_threshold_low, size_threshold_up, scale)\n",
    "    nucl_centroid_pred = nucl_centroid(nucleus_prediction)\n",
    "    # Calculate Euclidean distance between nucleus centroid and centroid of each FA\n",
    "    distance_pred = []\n",
    "    for i in range(len(fa_centroids_pred)):\n",
    "        distance_pred.append(euclidean_distance(nucl_centroid_pred[0], fa_centroids_pred[i]))\n",
    "    \n",
    "    # Calculate sum of Euclidean distances in ground truth and prediction\n",
    "    total_distance_truth = sum(distance_truth)\n",
    "    total_distance_pred = sum(distance_pred)\n",
    "    # Calculate FA-Nucleus Distribution score as ratio between sum of distances in ground truth and prediction\n",
    "    fa_nd = min(total_distance_truth, total_distance_pred)/max(total_distance_truth, total_distance_pred)\n",
    "    \n",
    "    return fa_nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where 3D cells are located\n",
    "test_dir = '3D_cells'\n",
    "cells = os.listdir(test_dir)\n",
    "# Store directory paths for each individual 3D cell in empty list\n",
    "cell_folders = []\n",
    "for i in range(len(cells)):\n",
    "    cell_folders.append(os.path.join(test_dir, 'cell{}'.format(i+1)))\n",
    "# Create empty list to store dpm, d, s, a, and pearson values for later calculation of average of each metric\n",
    "dpm_avg = []\n",
    "d_avg = []\n",
    "s_avg = []\n",
    "a_avg = []\n",
    "pearson_avg = []\n",
    "# Create empty list to store global and FA-Nucleus distribution score\n",
    "global_avg = []\n",
    "fa_nd_avg = []\n",
    "for folder in cell_folders:\n",
    "    for eval_folder in os.listdir(folder):\n",
    "        # Evaluate FA predictions located on fa subfolder using DPM\n",
    "        if eval_folder == 'fa':\n",
    "            img_folder = os.path.join(folder, eval_folder)\n",
    "            for image in os.listdir(img_folder):\n",
    "                if image == 'ground_truth.tiff':\n",
    "                    ground_truth = os.path.join(img_folder, image)\n",
    "                    ground_truth = io.imread(ground_truth)\n",
    "                    fa_truth = np.uint8(ground_truth)\n",
    "                    fa_truth_processed = np.uint8(ground_truth)\n",
    "                elif image == 'prediction.tiff':\n",
    "                    prediction = os.path.join(img_folder, image)        \n",
    "                    prediction = io.imread(prediction)\n",
    "                    fa_prediction = np.uint8(prediction)\n",
    "                    fa_prediction_processed = np.uint8(prediction)\n",
    "            dpm = dpm_3d(fa_truth, fa_prediction, 1, 4, 0.7, 0.33, 0.33, 0.33)\n",
    "            for i in range(len(fa_truth_processed)):\n",
    "                fa_truth_processed[i,:,:,1] = cv2.bitwise_and(fa_truth_processed[i,:,:,1], fa_truth_processed[i,:,:,1], mask=dpm[4])\n",
    "                fa_prediction_processed[i,:,:,1] = cv2.bitwise_and(fa_prediction_processed[i,:,0:256,1], fa_prediction_processed[i,:,:,1], mask=dpm[5])\n",
    "            dpm_avg.append(dpm[0]*100)\n",
    "            d_avg.append(dpm[1]*100)\n",
    "            s_avg.append(dpm[2]*100)\n",
    "            a_avg.append(dpm[3]*100)\n",
    "            print(folder)\n",
    "            print('FA: {}'.format(dpm[0]*100))\n",
    "        # Evaluate Nucleus predictions located on nucl subfolder using Pearson correlation\n",
    "        elif eval_folder == 'nucl':\n",
    "            img_folder = os.path.join(folder, eval_folder)\n",
    "            for image in os.listdir(img_folder):\n",
    "                if image == 'ground_truth.tiff':\n",
    "                    ground_truth_path = os.path.join(img_folder, image)\n",
    "                    ground_truth = io.imread(ground_truth_path)\n",
    "                    nucl_truth = ground_truth[:,:,:,2].flatten()\n",
    "                    nucl_truth = np.uint8(nucl_truth)\n",
    "                    membrane = ground_truth[:,:,:,0]\n",
    "                    nucleus_truth = ground_truth\n",
    "                    nucleus_truth = np.uint8(nucleus_truth)\n",
    "                    nucleus_truth_processed = nucleus_truth\n",
    "                    for i in range(len(nucleus_truth_processed)):\n",
    "                        ret, thresh = cv2.threshold(nucleus_truth_processed[i], 100, 255, cv2.THRESH_TOZERO)\n",
    "                        nucleus_truth_processed[i] = thresh\n",
    "                elif image == 'prediction.tiff':\n",
    "                    prediction_path = os.path.join(img_folder, image)\n",
    "                    prediction = io.imread(prediction_path)\n",
    "                    nucl_pred = prediction[:,:,:,2].flatten()\n",
    "                    nucl_pred = np.uint8(nucl_pred)\n",
    "                    nucleus_pred = prediction\n",
    "                    nucleus_pred = np.uint8(nucleus_pred)\n",
    "                    nucleus_pred_processed = nucleus_pred\n",
    "                    for i in range(len(nucleus_pred_processed)):\n",
    "                        ret, thresh = cv2.threshold(nucleus_pred_processed[i], 50, 255, cv2.THRESH_TOZERO)\n",
    "                        nucleus_pred_processed[i] = thresh\n",
    "            pearson_value = pearsonr(nucl_truth, nucl_pred)\n",
    "            pearson_avg.append(pearson_value[0]*100)\n",
    "            print('Nucl: {}'.format(pearson_value[0]*100))\n",
    "    # Calculate Global and FA-ND score\n",
    "    global_score = 0.5*pearson_value[0] + 0.5*dpm[0]\n",
    "    global_avg.append(global_score*100)\n",
    "    print('Global: {}'.format(global_score*100))\n",
    "    fa_nd_score = fa_nd(nucleus_truth, nucleus_pred, fa_truth, fa_prediction, 1, 4, 0.7)\n",
    "    fa_nd_avg.append(fa_nd_score*100)\n",
    "    print('FA-ND: {}'.format(fa_nd_score*100))\n",
    "    # Build digital twin using processed predicted Nucleus and FA sites and compare to true cell\n",
    "    for eval_folder in os.listdir(folder):\n",
    "        if eval_folder == 'visualize':\n",
    "            img_folder = os.path.join(folder, eval_folder)\n",
    "            panel = np.zeros((64, 256, 256*2+2, 3), dtype=np.uint8)\n",
    "            panel[:,:,0:256,0] = membrane\n",
    "            panel[:,:,256+2:256*2+2,0] = membrane\n",
    "            panel[:,:,0:256,1] = fa_truth_processed[:,:,:,1]\n",
    "            panel[:,:,256+2:256*2+2,1] = fa_prediction_processed[:,:,:,1]\n",
    "            panel[:,:,0:256,2] = nucleus_truth_processed[:,:,:,2]\n",
    "            panel[:,:,256+2:256*2+2,2] = nucleus_pred_processed[:,:,:,2]\n",
    "            new_img = np.zeros((3, 64, 256, 256*2+2), dtype=np.uint8)\n",
    "            new_img[0] = panel[:,:,:,1]\n",
    "            new_img[1] = panel[:,:,:,2]\n",
    "            new_img[2] = panel[:,:,:,0]\n",
    "            io.imsave((os.path.join(img_folder, 'cell_comparison.tiff')), panel)\n",
    "            io.imsave((os.path.join(img_folder, 'agave_cell_comparison.tiff')), new_img)\n",
    "# Calculate mean and standard deviation across all cells\n",
    "pearson_avg.append(statistics.mean(pearson_avg))\n",
    "dpm_avg.append(statistics.mean(dpm_avg))\n",
    "d_avg.append(statistics.mean(d_avg))\n",
    "s_avg.append(statistics.mean(s_avg))\n",
    "a_avg.append(statistics.mean(a_avg))\n",
    "global_avg.append(statistics.mean(global_avg))\n",
    "fa_nd_avg.append(statistics.mean(fa_nd_avg))\n",
    "pearson_avg.append(statistics.stdev(pearson_avg))\n",
    "dpm_avg.append(statistics.stdev(dpm_avg))\n",
    "d_avg.append(statistics.stdev(d_avg))\n",
    "s_avg.append(statistics.stdev(s_avg))\n",
    "a_avg.append(statistics.stdev(a_avg))\n",
    "global_avg.append(statistics.stdev(global_avg))\n",
    "fa_nd_avg.append(statistics.stdev(fa_nd_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "for i in range(len(cells)):\n",
    "    indices.append('Cell{}'.format(i+1))\n",
    "indices.append('Average')\n",
    "indices.append('Standard deviaton')\n",
    "df = pd.DataFrame({\n",
    "    \"Nucleus (PCC)\": pearson_avg,\n",
    "    \"FA (DPM)\": dpm_avg,\n",
    "    \"FA (d)\": d_avg,\n",
    "    \"FA (s)\": s_avg,\n",
    "    \"FA (a)\": a_avg,\n",
    "    \"Global\": global_avg,\n",
    "    \"FA-ND\": fa_nd_avg\n",
    "}, index = indices)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('3D_cells_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
